{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fellow', 'citizens', ',', 'the', 'will', 'of', 'the', 'American', 'people', ',', 'expressed', 'through', 'their', 'unsolicited', 'suffrages', ',', 'calls', 'me', 'before', 'you', 'to', 'pass', 'through', 'the', 'solemnities', 'preparatory', 'to', 'taking', 'upon', 'myself', 'the', 'duties', 'of', 'President', 'of', 'the', 'United', 'States', 'for', 'another', 'term', '.', 'For', 'their', 'approbation', 'of', 'my', 'public', 'conduct', 'through']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import inaugural\n",
    "inaugural.fileids()\n",
    "inj = inaugural.words(fileids = '1833-Jackson.txt')[:50]\n",
    "print(inj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fellow']\n",
      "[('Fellow', 'NN')]\n",
      "['citizens']\n",
      "[('citizens', 'NNS')]\n",
      "[',']\n",
      "[(',', ',')]\n",
      "['the']\n",
      "[('the', 'DT')]\n",
      "['will']\n",
      "[('will', 'MD')]\n",
      "['of']\n",
      "[('of', 'IN')]\n",
      "['the']\n",
      "[('the', 'DT')]\n",
      "['American']\n",
      "[('American', 'JJ')]\n",
      "['people']\n",
      "[('people', 'NNS')]\n",
      "[',']\n",
      "[(',', ',')]\n",
      "['expressed']\n",
      "[('expressed', 'VBN')]\n",
      "['through']\n",
      "[('through', 'IN')]\n",
      "['their']\n",
      "[('their', 'PRP$')]\n",
      "['unsolicited']\n",
      "[('unsolicited', 'JJ')]\n",
      "['suffrages']\n",
      "[('suffrages', 'NNS')]\n",
      "[',']\n",
      "[(',', ',')]\n",
      "['calls']\n",
      "[('calls', 'NNS')]\n",
      "['me']\n",
      "[('me', 'PRP')]\n",
      "['before']\n",
      "[('before', 'IN')]\n",
      "['you']\n",
      "[('you', 'PRP')]\n",
      "['to']\n",
      "[('to', 'TO')]\n",
      "['pass']\n",
      "[('pass', 'NN')]\n",
      "['through']\n",
      "[('through', 'IN')]\n",
      "['the']\n",
      "[('the', 'DT')]\n",
      "['solemnities']\n",
      "[('solemnities', 'NNS')]\n",
      "['preparatory']\n",
      "[('preparatory', 'NN')]\n",
      "['to']\n",
      "[('to', 'TO')]\n",
      "['taking']\n",
      "[('taking', 'VBG')]\n",
      "['upon']\n",
      "[('upon', 'IN')]\n",
      "['myself']\n",
      "[('myself', 'PRP')]\n",
      "['the']\n",
      "[('the', 'DT')]\n",
      "['duties']\n",
      "[('duties', 'NNS')]\n",
      "['of']\n",
      "[('of', 'IN')]\n",
      "['President']\n",
      "[('President', 'NNP')]\n",
      "['of']\n",
      "[('of', 'IN')]\n",
      "['the']\n",
      "[('the', 'DT')]\n",
      "['United']\n",
      "[('United', 'NNP')]\n",
      "['States']\n",
      "[('States', 'NNS')]\n",
      "['for']\n",
      "[('for', 'IN')]\n",
      "['another']\n",
      "[('another', 'DT')]\n",
      "['term']\n",
      "[('term', 'NN')]\n",
      "['.']\n",
      "[('.', '.')]\n",
      "['For']\n",
      "[('For', 'IN')]\n",
      "['their']\n",
      "[('their', 'PRP$')]\n",
      "['approbation']\n",
      "[('approbation', 'NN')]\n",
      "['of']\n",
      "[('of', 'IN')]\n",
      "['my']\n",
      "[('my', 'PRP$')]\n",
      "['public']\n",
      "[('public', 'NN')]\n",
      "['conduct']\n",
      "[('conduct', 'NN')]\n",
      "['through']\n",
      "[('through', 'IN')]\n"
     ]
    }
   ],
   "source": [
    "for text in inj:\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        print(words)\n",
    "        tagged = nltk.pos_tag(words)\n",
    "        print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fellow\n",
      "cit\n",
      ",\n",
      "the\n",
      "wil\n",
      "of\n",
      "the\n",
      "am\n",
      "peopl\n",
      ",\n",
      "express\n",
      "through\n",
      "their\n",
      "unsolicit\n",
      "suffr\n",
      ",\n",
      "cal\n",
      "me\n",
      "bef\n",
      "you\n",
      "to\n",
      "pass\n",
      "through\n",
      "the\n",
      "solemn\n",
      "prep\n",
      "to\n",
      "tak\n",
      "upon\n",
      "myself\n",
      "the\n",
      "duty\n",
      "of\n",
      "presid\n",
      "of\n",
      "the\n",
      "unit\n",
      "stat\n",
      "for\n",
      "anoth\n",
      "term\n",
      ".\n",
      "for\n",
      "their\n",
      "approb\n",
      "of\n",
      "my\n",
      "publ\n",
      "conduc\n",
      "through\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmerLan = LancasterStemmer()\n",
    "for text in inj:\n",
    "    stemm =  stemmerLan.stem(text) #finding stem for each words\n",
    "    print(stemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
