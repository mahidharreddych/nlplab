{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textblob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "text = TextBlob( \"\"\"Snowball is a small string processing language designed for creating stemming algorithms for use in Information Retrieval. \n",
    "This site describes Snowball, and presents several useful stemmers which have been implemented using it puppies.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Snowball is a small string processing language designed for creating stemming algorithms for use in Information Retrieval.\"),\n",
       " Sentence(\"This site describes Snowball, and presents several useful stemmers which have been implemented using it puppies.\")]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.sentences #here which they use regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Snowball', 'is', 'a', 'small', 'string', 'processing', 'language', 'designed', 'for', 'creating', 'stemming', 'algorithms', 'for', 'use', 'in', 'Information', 'Retrieval', 'This', 'site', 'describes', 'Snowball', 'and', 'presents', 'several', 'useful', 'stemmers', 'which', 'have', 'been', 'implemented', 'using', 'it', 'puppies'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.words #Here in Word tokenization , first text will tokenzie as sentence then to words\n",
    "            #they are using TreeBlankTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Snowball is a small string processing language designed for creating stemming algorithms for use in Information Retrieval. \\nThis site describes Snowball, and presents several useful stemmers which have been implemented using it puppies.'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can also use NLTK \n",
    "from nltk.tokenize import TabTokenizer\n",
    "tokenizer = TabTokenizer()\n",
    "blob = TextBlob( \"\"\"Snowball is a small string processing language designed for creating stemming algorithms for use in Information Retrieval. \n",
    "This site describes Snowball, and presents several useful stemmers which have been implemented using it puppies.\"\"\"\n",
    ", tokenizer = tokenizer)\n",
    "blob.tokens "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Snowball', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('small', 'JJ'),\n",
       " ('string', 'NN'),\n",
       " ('processing', 'NN'),\n",
       " ('language', 'NN'),\n",
       " ('designed', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('creating', 'VBG'),\n",
       " ('stemming', 'VBG'),\n",
       " ('algorithms', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('use', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Information', 'NNP'),\n",
       " ('Retrieval', 'NNP'),\n",
       " ('This', 'DT'),\n",
       " ('site', 'NN'),\n",
       " ('describes', 'VBZ'),\n",
       " ('Snowball', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('presents', 'NNS'),\n",
       " ('several', 'JJ'),\n",
       " ('useful', 'JJ'),\n",
       " ('stemmers', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('have', 'VBP'),\n",
       " ('been', 'VBN'),\n",
       " ('implemented', 'VBN'),\n",
       " ('using', 'VBG'),\n",
       " ('it', 'PRP'),\n",
       " ('puppies', 'VBZ')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tags #This is default POS Tagger in TextBlob called as PattrenTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Snowball', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('small', 'JJ'),\n",
       " ('string', 'NN'),\n",
       " ('processing', 'NN'),\n",
       " ('language', 'NN'),\n",
       " ('designed', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('creating', 'VBG'),\n",
       " ('stemming', 'VBG'),\n",
       " ('algorithms', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('use', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Information', 'NNP'),\n",
       " ('Retrieval', 'NNP'),\n",
       " ('This', 'DT'),\n",
       " ('site', 'NN'),\n",
       " ('describes', 'VBZ'),\n",
       " ('Snowball', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('presents', 'NNS'),\n",
       " ('several', 'JJ'),\n",
       " ('useful', 'JJ'),\n",
       " ('stemmers', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('have', 'VBP'),\n",
       " ('been', 'VBN'),\n",
       " ('implemented', 'VBN'),\n",
       " ('using', 'VBG'),\n",
       " ('it', 'PRP'),\n",
       " ('puppies', 'VBZ')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the second type with NLTKTagger \n",
    "from textblob import TextBlob\n",
    "from textblob.taggers import NLTKTagger\n",
    "nltk_tagger = NLTKTagger()\n",
    "blob = text\n",
    "pos_tagger = nltk_tagger\n",
    "blob.pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noun Phrase Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['snowball', 'small string processing language', 'information retrieval', 'snowball', 'useful stemmers'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.noun_phrases #This is the default NP extraction called FASTNPExtrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['snowball', 'small string processing language', 'information retrieval', 'snowball', 'useful stemmers'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the second metho NP extrator by using Conlletractor based CoNLL 2000 Corpus\n",
    "from textblob.np_extractors import ConllExtractor\n",
    "extractor = ConllExtractor()\n",
    "blob = text\n",
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.25, subjectivity=0.4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is a type of sentiment analyzer that which they used Pattren Analyzer\n",
    "test = TextBlob(\"Snowball is a small ball which we made and designed by using snow for to play and beat others in snow\")\n",
    "test.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.950945918761427, p_neg=0.04905408123857359)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this they used clasification menthod named NaiveBayes which gives (classification, p_pos, p_neg)\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "blob = TextBlob(\"Snowball is a small ball which we made and designed by using snow for to play and beat others in snow\", analyzer = NaiveBayesAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words Inflection and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Snowball', 'is', 'a', 'small', 'string', 'processing', 'language', 'designed', 'for', 'creating', 'stemming', 'algorithms', 'for', 'use', 'in', 'Information', 'Retrieval', 'This', 'site', 'describes', 'Snowball', 'and', 'presents', 'several', 'useful', 'stemmers', 'which', 'have', 'been', 'implemented', 'using', 'it', 'puppies'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#They perform word inflection like making singular into plural\n",
    "sentence = text\n",
    "sentence.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'algorithm'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[11].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'puppy'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[-1].singularize() #it hase ies in the ending it work good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'usefuls'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[-9].pluralize() #in plularizing it only adds \"S at the end whether it has plural form or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'designeds'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[7].pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goose'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatizing the words by using lemmatize funtion\n",
    "from textblob import Word\n",
    "w = Word(\"geese\")\n",
    "w.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'use'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word(\"using\")\n",
    "w.lemmatize(\"VBG\") #Pos_tagging of given word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('hack.n.01'),\n",
       " Synset('machine_politician.n.01'),\n",
       " Synset('hack.n.03'),\n",
       " Synset('hack.n.04'),\n",
       " Synset('cab.n.03'),\n",
       " Synset('hack.n.06'),\n",
       " Synset('hack.n.07'),\n",
       " Synset('hack.n.08'),\n",
       " Synset('chop.v.05'),\n",
       " Synset('hack.v.02'),\n",
       " Synset('hack.v.03'),\n",
       " Synset('hack.v.04'),\n",
       " Synset('hack.v.05'),\n",
       " Synset('hack.v.06'),\n",
       " Synset('hack.v.07'),\n",
       " Synset('hack.v.08')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in this we are trying get the different type of synonyms of words irrespetive of POS \n",
    "word = Word(\"hack\")\n",
    "word.synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chop.v.05'),\n",
       " Synset('hack.v.02'),\n",
       " Synset('hack.v.03'),\n",
       " Synset('hack.v.04'),\n",
       " Synset('hack.v.05'),\n",
       " Synset('hack.v.06'),\n",
       " Synset('hack.v.07'),\n",
       " Synset('hack.v.08')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"hack\").get_synsets(pos='v') #Here we getting only POS tag = VERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('hack.n.01'),\n",
       " Synset('machine_politician.n.01'),\n",
       " Synset('hack.n.03'),\n",
       " Synset('hack.n.04'),\n",
       " Synset('cab.n.03'),\n",
       " Synset('hack.n.06'),\n",
       " Synset('hack.n.07'),\n",
       " Synset('hack.n.08')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"hack\").get_synsets(pos='n') # getting only nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('travel.v.01'),\n",
       " Synset('go.v.02'),\n",
       " Synset('go.v.03'),\n",
       " Synset('become.v.01'),\n",
       " Synset('go.v.05'),\n",
       " Synset('run.v.05'),\n",
       " Synset('run.v.03'),\n",
       " Synset('proceed.v.04'),\n",
       " Synset('go.v.09'),\n",
       " Synset('go.v.10'),\n",
       " Synset('sound.v.02'),\n",
       " Synset('function.v.01'),\n",
       " Synset('run_low.v.01'),\n",
       " Synset('move.v.13'),\n",
       " Synset('survive.v.01'),\n",
       " Synset('go.v.16'),\n",
       " Synset('die.v.01'),\n",
       " Synset('belong.v.03'),\n",
       " Synset('go.v.19'),\n",
       " Synset('start.v.09'),\n",
       " Synset('move.v.15'),\n",
       " Synset('go.v.22'),\n",
       " Synset('go.v.23'),\n",
       " Synset('blend.v.02'),\n",
       " Synset('go.v.25'),\n",
       " Synset('fit.v.02'),\n",
       " Synset('rifle.v.02'),\n",
       " Synset('go.v.28'),\n",
       " Synset('plump.v.04'),\n",
       " Synset('fail.v.04')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob.wordnet import VERB #anthor way of representing With POS \n",
    "word = Word(\"went\")\n",
    "word.synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a form of entertainment that enacts a story by sound and a sequence of images giving the illusion of continuous movement',\n",
       " 'a medium that disseminates moving pictures',\n",
       " 'photographic material consisting of a base of celluloid covered with a photographic emulsion; used to make negatives or transparencies',\n",
       " 'a thin coating or layer',\n",
       " 'a thin sheet of (usually plastic and usually transparent) material used to wrap or cover things',\n",
       " 'make a film or photograph of something',\n",
       " 'record in film']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"film\").definitions #getting definations from wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the similarity between two different words\n",
    "from textblob.wordnet import Synset\n",
    "hack = Synset('hack.v.03')\n",
    "went = Synset('run.v.03')\n",
    "hack.path_similarity(went)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hack = Synset('hack.v.03')\n",
    "hack = Synset('machine_politician.n.01')\n",
    "hack.path_similarity(hack) #this works great "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twy Her!\n"
     ]
    }
   ],
   "source": [
    "#Doing spelling correction by using Correction() method\n",
    "sent = TextBlob(\"Hwy Therw!\") #i type HEY THERE\n",
    "print(sent.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('falling', 0.4778761061946903),\n",
       " ('filling', 0.26548672566371684),\n",
       " ('failing', 0.25663716814159293)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spelling correction by using spellcorection() method\n",
    "from textblob import Word\n",
    "w = Word('faillling') #I typed failing\n",
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Twy', 0.75), ('Dwy', 0.25)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word('Hwy') # i typed Hey  \n",
    "\n",
    "w.spellcheck()\n",
    "##They already mentioned spelling correction is only working with 70% accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word and Noun Phrase Frequencies Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.word_counts['for'] #count of word in TextBlob text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.words.count('FOR', case_sensitive=True) #count with case sensitive on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['snowball', 'small string processing language', 'information retrieval', 'snowball', 'useful stemmers'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.noun_phrases #list of NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.noun_phrases.count('snowball') #count of NP snowball"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Snowball', 'is', 'a']),\n",
       " WordList(['is', 'a', 'small']),\n",
       " WordList(['a', 'small', 'string']),\n",
       " WordList(['small', 'string', 'processing']),\n",
       " WordList(['string', 'processing', 'language']),\n",
       " WordList(['processing', 'language', 'designed']),\n",
       " WordList(['language', 'designed', 'for']),\n",
       " WordList(['designed', 'for', 'creating']),\n",
       " WordList(['for', 'creating', 'stemming']),\n",
       " WordList(['creating', 'stemming', 'algorithms']),\n",
       " WordList(['stemming', 'algorithms', 'for']),\n",
       " WordList(['algorithms', 'for', 'use']),\n",
       " WordList(['for', 'use', 'in']),\n",
       " WordList(['use', 'in', 'Information']),\n",
       " WordList(['in', 'Information', 'Retrieval']),\n",
       " WordList(['Information', 'Retrieval', 'This']),\n",
       " WordList(['Retrieval', 'This', 'site']),\n",
       " WordList(['This', 'site', 'describes']),\n",
       " WordList(['site', 'describes', 'Snowball']),\n",
       " WordList(['describes', 'Snowball', 'and']),\n",
       " WordList(['Snowball', 'and', 'presents']),\n",
       " WordList(['and', 'presents', 'several']),\n",
       " WordList(['presents', 'several', 'useful']),\n",
       " WordList(['several', 'useful', 'stemmers']),\n",
       " WordList(['useful', 'stemmers', 'which']),\n",
       " WordList(['stemmers', 'which', 'have']),\n",
       " WordList(['which', 'have', 'been']),\n",
       " WordList(['have', 'been', 'implemented']),\n",
       " WordList(['been', 'implemented', 'using']),\n",
       " WordList(['implemented', 'using', 'it']),\n",
       " WordList(['using', 'it', 'puppies'])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.ngrams(n=3) #getting the list of 3 successive words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
